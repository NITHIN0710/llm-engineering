{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b556d713",
   "metadata": {},
   "source": [
    "## *Working with Gradio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedf9aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39da926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shout(text):\n",
    "    print(f\"Shout has been called with input {text}\")\n",
    "    return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e9d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869fc263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a little more\n",
    "\n",
    "message_input = gr.Textbox(label=\"Your message\", info=\"Enter a message to be shouted\", lines=7)\n",
    "message_output = gr.Textbox(label=\"Response\", lines=7)\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=shout,\n",
    "    title=\"Shout\",\n",
    "    inputs=[message_input],\n",
    "    outputs=[message_output],\n",
    "    examples=[\"hello\", \"woah!\"],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch(share=True, inbrowser=True, auth=(\"nithin\", \"0704\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a907cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now getting llm to answer\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe3a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "gemini = OpenAI(base_url=GEMINI_BASE_URL, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b9d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant that provides friendly responses to user queries.\"\n",
    "\n",
    "def message_gemini(prompt):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": prompt}]\n",
    "    response = gemini.chat.completions.create(model='gemini-2.5-flash-lite', messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2075a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = gr.Textbox(label=\"Your Message\", info=\"Ask anything..\", lines = 7)\n",
    "message_output = gr.Textbox(label=\"Response\", lines=8)\n",
    "view = gr.Interface(\n",
    "    fn=message_gemini,\n",
    "    title='Gemini 2.5 Flash Lite',\n",
    "    inputs=[message_input],\n",
    "    outputs=[message_output],\n",
    "    examples=[\"Hello gemini\", \"What is AI?\"],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7687b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting response in Markdown instead of in Textbox\n",
    "\n",
    "message_input = gr.Textbox(label=\"Your message\", info=\"Ask Anything..\", lines=7)\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "view = gr.Interface(\n",
    "    fn=message_gemini,\n",
    "    title=\"Gemini 2.5 Flash Lite\",\n",
    "    inputs=[message_input],\n",
    "    outputs=[message_output],\n",
    "    examples=[\n",
    "        \"Explain the Transformer architecture to a layperson\",\n",
    "        \"Explain the Transformer architecture to an aspiring AI engineer\",\n",
    "        ], \n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets stream the response of gemini 2.5 flash lite\n",
    "\n",
    "def stream_gemini(prompt):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": prompt}]\n",
    "    stream = gemini.chat.completions.create(\n",
    "        model='gemini-2.5-flash-lite',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab42543",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = gr.Textbox(label=\"Your message\", info=\"Ask Anything..\", lines=7)\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "view = gr.Interface(\n",
    "    fn=stream_gemini,\n",
    "    title=\"Gemini 2.5 Flash Lite\",\n",
    "    inputs=[message_input],\n",
    "    outputs=[message_output],\n",
    "    examples=[\n",
    "        \"Explain the Transformer architecture to a layperson\",\n",
    "        \"Explain the Transformer architecture to an aspiring AI engineer\",\n",
    "        ], \n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27015c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_BASE_URL = \"https://api.groq.com/openai/v1\"\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "\n",
    "groq = OpenAI(base_url=GROQ_BASE_URL, api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b387e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_groq_llama(prompt):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": prompt}]\n",
    "    response = groq.chat.completions.create(\n",
    "        model='llama-3.1-8b-instant',\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98143e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = gr.Textbox(label=\"Your message\", info=\"Ask Anything..\", lines=7)\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "view = gr.Interface(\n",
    "    fn=message_groq_llama,\n",
    "    title=\"GROQ LLAMA\",\n",
    "    inputs=[message_input],\n",
    "    outputs=[message_output],\n",
    "    examples=[\n",
    "        \"Explain the Transformer architecture to a layperson\",\n",
    "        \"Explain the Transformer architecture to an aspiring AI engineer\",\n",
    "        ], \n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b84d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_groq_openai(prompt):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": prompt}]\n",
    "    response = groq.chat.completions.create(\n",
    "        model='openai/gpt-oss-20b',\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c50c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = gr.Textbox(label=\"Your message\", info=\"Ask Anything..\", lines=7)\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "view = gr.Interface(\n",
    "    fn=message_groq_openai,\n",
    "    title=\"GROQ OPENAI\",\n",
    "    inputs=[message_input],\n",
    "    outputs=[message_output],\n",
    "    examples=[\n",
    "        \"Explain the Transformer architecture to a layperson\",\n",
    "        \"Explain the Transformer architecture to an aspiring AI engineer\",\n",
    "        ], \n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ffdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(prompt, model):\n",
    "    if model == \"GROQ LLAMA\":\n",
    "        result = message_groq_llama(prompt)\n",
    "    elif model == \"GROQ OPENAI\":\n",
    "        result = message_groq_openai(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown Model\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4589a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = gr.Textbox(label=\"Your message\", info=\"Ask anything..\", lines=7)\n",
    "model_selector = gr.Dropdown([\"GROQ LLAMA\", \"GROQ OPENAI\"], label=\"Select model\", value=\"GROQ LLAMA\")\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=select_model,\n",
    "    title=\"LLMs\",\n",
    "    inputs=[message_input, model_selector],\n",
    "    outputs=[message_output],\n",
    "    examples=[\n",
    "            [\"Explain the Transformer architecture to a layperson\", \"GROQ LLAMA\"],\n",
    "            [\"Explain the Transformer architecture to an aspiring AI engineer\", \"GROQ OPENAI\"]\n",
    "        ], \n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch(share=True, inbrowser=True, auth=(\"nithin\", \"0704\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
